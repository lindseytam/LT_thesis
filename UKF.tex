\chapter{Unscented Kalman Filters}
\label{Unscented Kalman Filters}

The Unscented Kalman Filter (UKF) does not require using Jacobians to linearize non-linear functions. Instead, the UKF uses the Unscented Transform (UT). This process involves using sigma points, which are represented in a Sigma Point Matrix and represent the normal distribution of the data. The number of sigma points is deterministic and depends on the dimensions of the system. In general, a UFK will have 2 $d_x$ + 1 sigma points, where $d_x$ represents the dimension of the state vector \cite{inbook, inproceedings, Wan01theunscented}. The covariance and weights of these sigma points are calculated. These sigma points undergo a non-linear transformation, resulting in a posterior distribution that is not normal \cite{inbook, Wan01theunscented} . We are able to approximate the normal distribution of the posterior distribution using the weights and covariance that were calculated prior to the transformation. \\ \\
\begin{center}
    
\centering
\begin{tabular}{ |p{2cm}||p{5cm}|p{2cm}| }
    \hline
    \multicolumn{3}{|c|}{Variables in the Unscented Kalman Filter } \\ 
    \hline
    Variable & Description & Dimensions \\
    \hline
    x & Vector containing state variables & $d_x \times 1 $\\ 
    $\chi $& Sigma Point Matrix &$ d_x \times 2 d_x + 1 $\\
    F & State Transition Matrix  & $d_x \times d_x $  \\ 
    H & Observation Matrix & $d_y \times d_x$\\
    G & Input Matrix & $d_x \times d_u$\\
    u & Input Vector  & $d_u \times 1$\\
    P & Covariance matrix & $d_x \times d_x $  \\
    k & Time step  & $1 \times 1$\\
    w & Process Noise Vector & $d_x \times 1$\\
    $\alpha$ & Controls spread of sigma points & $0 <  \alpha < 1$ \\
    $\beta$ & Adjust sigma point weight & $0 \leq  \beta$ \\
    $\kappa $ & Sigma point weighting constant & $0, 3 - d_q, 0 \leq \kappa \leq 3$ \\
    $\lambda $ & Scaling parameter for sigma point weights & scalar \\
    \hline
\end{tabular}
\end{center}

\begin{enumerate}
    \item Initialize state vector and covariance
    \begin{align}
        \hat{x}_{0} &= \mathbb{E}[x_{0}] \\
        P_{x_{0}} &= \mathbb{E}[(x_{0}-\hat{x}_{0})(x_{0}-\hat{x}_{0})^{T}] 
    \end{align}
    \item Calculate sigma points
    \begin{align}
        \chi_{\ 0,k-1} &= \hat{x}_{k-1} \\
        \chi_{\ i,k-1} &= \hat{x}_{k-1} + (\sqrt{(n_{x}+\lambda_{x})P_{x_{k-1}}})_{i}, &  i=1,\dots,n_{x} \\
        \chi_{\ i,k-1} &= \hat{x}_{k-1} - (\sqrt{(n_{x}+\lambda_{x})P_{x_{k-1}}})_{i},  &  i=n_{x}+1,\dots,2n_{x},
    \end{align}
    \item Calculate the weights for each sigma point \\ \\
    Weights can have positive or negative values, but will ultimately sum to 1 \cite{article6}
    \begin{align}
        \lambda_{x} = \alpha_{x}^{2}(n_{x}+\kappa_{x})-n_{x} \\
        W^{(m)}_{x,0} = \frac{\lambda_{x}}{n_{x}+ \lambda_{x} } \\
        W^{(c)}_{x,0} = \frac{\lambda_{x}}{n_{x}+ \lambda_{x} } + (1 - \alpha^{2}_{x} + \beta_{x}) \\
        W^{(m)}_{x,i} = W^{(c)}_{x,i} = \frac{\lambda_{x}}{2(n_{x}+ \lambda_{x}) }, & i=1,\dots,2n_{x} \\
        W^{\text{aug,}(m)}_{x,0} = \frac{\lambda_{x}}{2n_{x}+ \lambda_{x} } \\
        W^{\text{aug,}(c)}_{x,0} = \frac{\lambda_{x}}{2n_{x}+ \lambda_{x} } + (1 - \alpha^{2}_{x} + \beta_{x}) \\
        W^{\text{aug,}(m)}_{x,i} = W^{\text{aug,}(c)}_{x,i} = \frac{\lambda_{x}}{2(2n_{x}+ \lambda_{x}) }, &  i=1,\dots,4n_{x} \\
    \end{align}
    \item Perform a non-linear transformation on the sigma points
    \begin{align}
        \hat{w}_{k} &= \hat{w}_{k-1} \\
        \chi^{*}_{\ i,k|k-1} &= f(\chi_{\ i,k-1},\hat{w}_{k-1})
    \end{align}
    \item Calculate the mean and covariance of the transformed sigma points
    \begin{align}
        \hat{x}^{*}_{\ k|k-1} &= \sum_{i=0}^{2n_{x}} W^{(m)}_{x,i} \chi^{*}_{\ i, k|k-1} \\
        P_{x_{k|k-1}} &=  \sum_{i=0}^{2n_{x}} W^{(c)}_{x,i} (\chi^{*}_{\ i, k|k-1} - \hat{x}^{*}_{\ k|k-1})(\chi^{*}_{\ i, k|k-1} - \hat{x}^{*}_{\ k|k-1})^{T} + R_{v} % Q_k is same as R_{v} (Process Noise Covariance)
    \end{align}
    \item Re-calculate sigma points
    \begin{align}
        \chi_{\ i, k|k-1} = \chi^{*}_{\ i,k|k-1}, & i=0,...,2n_{x} \\
        \chi_{\ i, k|k-1} = \chi^{*}_{\ 0,k|k-1} + (\sqrt{(n_{x}+\lambda_{x})P_{x_{k|k-1}}})_{i},  & i=2n_{x}+1,\dots,3n_{x} \\
        \chi_{\ i, k|k-1} = \chi^{*}_{\ 0,k|k-1} - (\sqrt{(n_{x}+\lambda_{x})P_{x_{k|k-1}}})_{i}, &  i=3n_{x}+1,\dots,4n_{x}
    \end{align}
    \item Generate prediction
    \begin{align}
        \hat{x}_{k|k-1} = \sum_{i=0}^{4n_{x}} W^{\text{aug,}(m)}_{x,i} \chi_{\ i, k|k-1} \\
        \mathcal{Y}_{k|k-1} = h(\chi_{k|k-1},\hat{w_{k}}) \\
        \hat{y}_{k|k-1} = \sum_{i=0}^{4n_{x}} W^{\text{aug,}(m)}_{x,i} \mathcal{Y}_{\ i, k|k-1}
    \end{align}
    \item Calculate Kalman Gain
    \begin{align}
        P_{y_{k}} = \sum_{i=0}^{4n_{x}} W^{\text{aug,}(c)}_{x,i} (\mathcal{Y}_{i, k|k-1} - \hat{y}_{k|k-1})(\mathcal{Y}_{i, k|k-1} - \hat{y}_{k|k-1})^{T} + R_{n}  \\ %R_k is the same as R_{n} (Measurement Noise Covariance)
        P_{x_{k}y_{x}} = \sum_{i=0}^{4n_{x}} W^{\text{aug,}(c)}_{x,i} (\chi_{\ i, k|k-1} - \hat{x}^{*}_{\ k|k-1})(\mathcal{Y}_{i, k|k-1} - \hat{y}_{k|k-1})^{T} \\
        K_{k} = P_{x_{k}y_{x}}P^{-1}_{y_{k}}
    \end{align}
    \item Update Estimate and state covariance
    \begin{equation}
        P_{x_{k}} = P_{x_{k|k-1}} - K_{k}P_{y_{k}}K^{-1}_{k} 
    \end{equation}
    \begin{equation}
        \hat{x}_{k} = \hat{x}_{k|k-1} + K_{k}(y_{k}-\hat{y}_{k|k-1}),
    \end{equation}
    
\end{enumerate}