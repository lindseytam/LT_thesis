\chapter{Extended Kalman Filters}
\label{Extended Kalman Filters}

The Extended Kalman Filter (EKF) is the non-linear version of the Kalman Filter. Though it can be used for non linear equations, it is important to note that it is not an optimal estimator. For the most part, the EKF Algorithm is nearly identical to the KF algorithm. The critical difference is in linearizing the state and observation function. The EKF uses the Jacobean to linearly approximate the non-linear function around the mean of the Gaussian distribution. Skipping this step would result in the transformed data being non-Gaussian; though taking the Jacobean enables the transformation to remain Gaussian, but it is not exact, resulting in some generalization. Linear approximation through a single point also makes the EKF inefficient when dealing with complex, higher order systems. Because of this, the model is highly subject to error, which can be somewhat reduced by setting accurate initial values. Though these flaws exist, the EKF performs strongly with applications of real time spatial fields, including navigation and positioning systems.  \\ \\

\section{Extended Kalman Filter Algorithm}



\begin{enumerate}
  \item Begin by initializing the state estimate, $x_0$, and the initial covariance matrix, $P_0$. Similar to the KF, the initial state estimate can be found by 
  \begin{align*}
       % \hat x_0 = \mathbb{E}[x_0]  = \begin{bmatrix}
         %  x_1 \\
           %\vdots \\
          % x_n 
         %\end{bmatrix}  
           \mathbb{E}[x_0]   = \sum^n_{i = a} x_i p_i = [x_a p_a + x_b p_b + \hdots + x_n p_n]^T,
      \end{align*}
 \noindent where  $x_a, x_b, \hdots, x_n$ are the state variable, $p_a, p_b, \hdots, p_n$ is the probability of getting each state variable, and T is the transpose of this row vector. We also want to initialize the covariance matrix by

    
  \begin{align*}
      P_0 =
      \begin{bmatrix}
           var(x_a)  & \hdots & cov(x_a,x_n) \\
           \vdots & \ddots & \vdots \\
           cov(x_n, x_a)  & \hdots & var(x_n )
         \end{bmatrix} .
  \end{align*}  
  
  Often, $P_0 $ will be initialized as a diagonal matrix with the diagonals being the variance of each state variance and every other value being set to 0.
  
  
  \item This next step deviates from the Kalman Filter because it takes a linear approximation the non-linear function by calculating the Jacobean. Recall that $F$ is the system state function, which is a model of the system. Let $f$ be the linearized representation of $F$ by taking the Jacobean as shown below:
  \begin{align*}
      F= \frac{\partial f}{\partial x} =
      \begin{bmatrix}
           \frac{\partial f_1}{\partial x_1} & \hdots & \frac{\partial f_n}{\partial x_n} \\
           \vdots & \ddots & \vdots \\
           \frac{\partial f_n}{\partial x_1}  & \hdots & \frac{\partial f_n}{\partial x_n}
         \end{bmatrix}  .
  \end{align*}
  
  
  Similarly, the observation function $H$ is a nonlinear, but a linear approximation, $h$, can be found by
  \begin{align*}
      H = \frac{\partial h}{\partial x} =
     \begin{bmatrix}
           \frac{\partial h_1}{\partial x_1} & \hdots & \frac{\partial h_1}{\partial x_n} \\
           \vdots & \ddots & \vdots \\
           \frac{\partial h_m}{\partial x_1}  & \hdots & \frac{\partial h_{m}}{\partial x_n}
         \end{bmatrix}  .
  \end{align*}
   Here, both $f$ and $h$ have no closed form solution. $f$ is the non-linear state function and $F$ is the linear approximation of $f$ with dimension $d_x$. Similarly, $h$ is the non linear observation while $H$ is linearized observation with dimension $d_y$. 
   
   
   
  \item A prediction can be generated by using the linear approximation, $f$, by
  \begin{align*}
      x_{k+1} = f( x_{k-1} , u_{k-1})  ,
  \end{align*} 
  where $u_{k-1}$ are the system outputs \textcolor{red}{expand more on what this is}. 
  
  
  
  \item Now, we can use the state covariance matrix, $P_{k | k - 1}$, to calculate Kalman Gain, $K_k$.  Recall that the Kalman Gain is a method to determine whether to place more weight on incoming measurements or the system's model. $P_{k | k - 1}$, can be found by
    \begin{align*} 
        P_{k | k -1} = F P_{k - 1} F^T + Q_{k-1} ,
        \end{align*}
        
       where $F$ is the nonlinear state function, $P_{k - 1} $ is the state covariance at the last time step, $T$ is the transpose, and $Q$ is the process noise covariance. Using this value, calculate the Kalman Gain by
         \begin{align*} 
        K_k = P_{k | k - 1} H^T_K (H_k P_{k | k - 1} H^T_K + R_k)^{-1},
    \end{align*}
    where $H$ is the nonlinear observation matrix, and $R$ is the measurement noise covariance.
    Recall that $H$ and $F$ are linear approximations of $f$ and $h$. Therefore, it is assumed that there is some amount of error when calculating the Kalman Gain.
    
    
 
    \item  The correction of the prediction is similar to the Kalman Filter. Incoming measurements from the system, $y_k$, need to be converted in order to facilitate a comparison with our state variables. Let the converted measurement be denoted $\hat y_k$ such that 
    \begin{align*}
        \hat y_k = h( x_k + v_k ),
    \end{align*}
   $h$ is the linear approximation of the observation function and $v_k$ is measurement noise. Using $\hat y_k$ , we can calculate the residual, which is a measure of how close the estimate is the measured values. The equation can be updated by 
     \begin{align*} 
        x_k = x_{k - 1} + K_k(y_k - \hat y_k).
    \end{align*}
    
    
    \item Finally, update the covariance matrix, $P_k $, which will be used in the next iteration of the filter. $P_k $ can be updated by
    \begin{align*} 
        P_k = (I - K_K H_k) P_{k | k-1},
    \end{align*}
    where $I$ is the identity matrix, $K_k$ is the Kalman Gain, $P_{k | k-1}$ is the covariance matrix given the last time step, and $H_k$ is the nonlinear observation matrix.
\end{enumerate} 

\newpage

\begin{center}
    
\centering
\begin{tabular}{ |p{2cm}||p{5cm}|p{2cm}| }
    \hline
    \multicolumn{3}{|c|}{Variables in the Extended Kalman Filter } \\ 
    \hline
    Variable & Description & Dimensions \\
    \hline
   x & State variables  & $d_x \times 1$ \\
    y & Output vector  & $d_y \times 1$ \\
    u & System inputs  & $d_u \times 1$\\
    v & Measurement noise & $d_y \times 1$\\
    w & Process noise & $d_x \times 1$\\
    f & None linear state function  & $d_x \times d_x $  \\ 
    F & State function  & $d_x \times d_x $  \\ 
    h & Non linear observation function & $d_y \times d_x$\\
    H & Linearized observation function & $d_y \times d_x$\\
    K & Kalman Gain  & $d_x \times d_y$\\
    Q & Process noise covariance  & $d_x \times d_x$ \\
    R & Measurement noise covariance &  $d_y \times d_y$\\
    P & Covariance matrix & $d_x \times d_x $  \\ 
    \hline
\end{tabular}
\end{center}
